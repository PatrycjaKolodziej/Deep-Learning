{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3ex_xf2Bya"
      },
      "source": [
        "# Classification (Wine dataset)\n",
        "\n",
        "This is a copy of UCI ML Wine recognition datasets. https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
        "\n",
        "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine.\n",
        "\n",
        "Features:\n",
        "* Alcohol\n",
        "* Malic acid\n",
        "* Ash\n",
        "* Alcalinity of ash\n",
        "* Magnesium\n",
        "* Total phenols\n",
        "* Flavanoids\n",
        "* Nonflavanoid phenols\n",
        "* Proanthocyanins\n",
        "* Color intensity\n",
        "* Hue\n",
        "* OD280/OD315 of diluted wines\n",
        "* Proline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkUzNa-V2Byc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Geq8ebdj2Bye"
      },
      "outputs": [],
      "source": [
        "wine_dataset = load_wine()\n",
        "X = pd.DataFrame(wine_dataset.data, columns=wine_dataset.feature_names)\n",
        "y = wine_dataset.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "kqADZ90Q2Byf",
        "outputId": "7ff341e7-b480-46bb-f988-88491d7cb80b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91980ed9-05bf-4b95-82ac-197d40f4fac5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91980ed9-05bf-4b95-82ac-197d40f4fac5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91980ed9-05bf-4b95-82ac-197d40f4fac5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91980ed9-05bf-4b95-82ac-197d40f4fac5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YvsMRZk21xH",
        "outputId": "e11a85c6-f78c-4659-efd3-4ae414fec41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u7UsfBd2Byf"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 1.1</b><br>\n",
        "Przeskaluj dane korzystając ze StandardScalera.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Gr4wQeRc2Byg",
        "outputId": "a93d52ef-a91b-47aa-acd8-3016a968194f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
              "0  1.518613   -0.562250  0.232053          -1.169593   1.913905   \n",
              "1  0.246290   -0.499413 -0.827996          -2.490847   0.018145   \n",
              "2  0.196879    0.021231  1.109334          -0.268738   0.088358   \n",
              "3  1.691550   -0.346811  0.487926          -0.809251   0.930918   \n",
              "4  0.295700    0.227694  1.840403           0.451946   1.281985   \n",
              "\n",
              "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "0       0.808997    1.034819             -0.659563         1.224884   \n",
              "1       0.568648    0.733629             -0.820719        -0.544721   \n",
              "2       0.808997    1.215533             -0.498407         2.135968   \n",
              "3       2.491446    1.466525             -0.981875         1.032155   \n",
              "4       0.808997    0.663351              0.226796         0.401404   \n",
              "\n",
              "   color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
              "0         0.251717  0.362177                      1.847920  1.013009  \n",
              "1        -0.293321  0.406051                      1.113449  0.965242  \n",
              "2         0.269020  0.318304                      0.788587  1.395148  \n",
              "3         1.186068 -0.427544                      1.184071  2.334574  \n",
              "4        -0.319276  0.362177                      0.449601 -0.037874  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e16e491-042e-4449-a43e-1f4368d753ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.518613</td>\n",
              "      <td>-0.562250</td>\n",
              "      <td>0.232053</td>\n",
              "      <td>-1.169593</td>\n",
              "      <td>1.913905</td>\n",
              "      <td>0.808997</td>\n",
              "      <td>1.034819</td>\n",
              "      <td>-0.659563</td>\n",
              "      <td>1.224884</td>\n",
              "      <td>0.251717</td>\n",
              "      <td>0.362177</td>\n",
              "      <td>1.847920</td>\n",
              "      <td>1.013009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.246290</td>\n",
              "      <td>-0.499413</td>\n",
              "      <td>-0.827996</td>\n",
              "      <td>-2.490847</td>\n",
              "      <td>0.018145</td>\n",
              "      <td>0.568648</td>\n",
              "      <td>0.733629</td>\n",
              "      <td>-0.820719</td>\n",
              "      <td>-0.544721</td>\n",
              "      <td>-0.293321</td>\n",
              "      <td>0.406051</td>\n",
              "      <td>1.113449</td>\n",
              "      <td>0.965242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.196879</td>\n",
              "      <td>0.021231</td>\n",
              "      <td>1.109334</td>\n",
              "      <td>-0.268738</td>\n",
              "      <td>0.088358</td>\n",
              "      <td>0.808997</td>\n",
              "      <td>1.215533</td>\n",
              "      <td>-0.498407</td>\n",
              "      <td>2.135968</td>\n",
              "      <td>0.269020</td>\n",
              "      <td>0.318304</td>\n",
              "      <td>0.788587</td>\n",
              "      <td>1.395148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.691550</td>\n",
              "      <td>-0.346811</td>\n",
              "      <td>0.487926</td>\n",
              "      <td>-0.809251</td>\n",
              "      <td>0.930918</td>\n",
              "      <td>2.491446</td>\n",
              "      <td>1.466525</td>\n",
              "      <td>-0.981875</td>\n",
              "      <td>1.032155</td>\n",
              "      <td>1.186068</td>\n",
              "      <td>-0.427544</td>\n",
              "      <td>1.184071</td>\n",
              "      <td>2.334574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.295700</td>\n",
              "      <td>0.227694</td>\n",
              "      <td>1.840403</td>\n",
              "      <td>0.451946</td>\n",
              "      <td>1.281985</td>\n",
              "      <td>0.808997</td>\n",
              "      <td>0.663351</td>\n",
              "      <td>0.226796</td>\n",
              "      <td>0.401404</td>\n",
              "      <td>-0.319276</td>\n",
              "      <td>0.362177</td>\n",
              "      <td>0.449601</td>\n",
              "      <td>-0.037874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e16e491-042e-4449-a43e-1f4368d753ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e16e491-042e-4449-a43e-1f4368d753ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e16e491-042e-4449-a43e-1f4368d753ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, index = X.index, columns=X.columns)\n",
        "X_scaled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKV2inz2Byg"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 1.2</b><br>\n",
        "Dokonaj podziału zbioru danych na zbiór treningowy i testowy <u>ze stratyfikacją</u>, odkładając 20% obserwacji do zbioru testowego.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOK1wJdE2Byh"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEh0l3fg2Byh"
      },
      "source": [
        "Architektura perceptrona"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz6-dqcq2Byi"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 2.1</b><br>\n",
        "Przygotuj klasyfikator modelu perceptrona wielowarstwowego o poniższych cechach:\n",
        "<ul>\n",
        "<li>architektura składająca się z 2 warstw ukrytych:</li>\n",
        "    <ul>\n",
        "    <li>pierwsza warstwa ukryta o 8 neuronach</li>\n",
        "    <li>druga warstwa ukryta o 4 neuronach</li>\n",
        "    </ul>\n",
        "<li>funkcja aktywacji dla warstw ukrytych: relu</li>\n",
        "<li>optymalizator wag neuronów (solver): adam</li>\n",
        "<li>maksymalna liczba iteracji: 1000</li>\n",
        "<li>rozmiar wsadu (batch size): 32</li>\n",
        "<li>ziarno losowości (random_state): 42</li>\n",
        "</ul>\n",
        "Wytrenuj model na wystandaryzowanych danych treningowych.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd-0H0SV2Byi"
      },
      "outputs": [],
      "source": [
        "clf_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(8, 4),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    batch_size=32,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "gvaEmUGA2Byj",
        "outputId": "13bf3b68-92c3-4c2f-ee36-6bd043419e1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(batch_size=32, hidden_layer_sizes=(8, 4), max_iter=1000,\n",
              "              random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=32, hidden_layer_sizes=(8, 4), max_iter=1000,\n",
              "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=32, hidden_layer_sizes=(8, 4), max_iter=1000,\n",
              "              random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "clf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zva8XEt22Byj"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 2.2</b><br>\n",
        "Dokonaj prognozy zbioru testowego. <br>\n",
        "Zweryfikuj metryki klasyfikacji trafności, czułości, precyzji itp (np. korzystając z funkcji <code>classification_report</code>).</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq_aWkzK2Byk"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD4T9Qr22Byk",
        "outputId": "1945dfab-19a3-4dc8-a18d-f12f76436cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.97      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-_3gZO2Byk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 3.1</b><br>\n",
        "Przygotuj klasyfikator modelu perceptrona wielowarstwowego o poniższych cechach:\n",
        "<ul>\n",
        "<li>architektura składająca się z 1 warstwy ukrytej:</li>\n",
        "    <ul>\n",
        "    <li>warstwa ukryta o 8 neuronach</li>\n",
        "    </ul>\n",
        "<li>funkcja aktywacji dla warstw ukrytych: relu</li>\n",
        "<li>optymalizator wag neuronów (solver): adam</li>\n",
        "<li>maksymalna liczba iteracji: 1000</li>\n",
        "<li>rozmiar wsadu (batch size): 64</li>\n",
        "<li>ziarno losowości (random_state): 42</li>\n",
        "</ul>\n",
        "Wytrenuj model na wystandaryzowanych danych treningowych.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRW9A0Cm2Byl"
      },
      "outputs": [],
      "source": [
        "clf_model_2 = MLPClassifier(\n",
        "    hidden_layer_sizes=(8),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    batch_size=64,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "l7LQPAZl2Bym",
        "outputId": "424eb9e4-57a7-4748-c231-6b7eb43a0a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(batch_size=64, hidden_layer_sizes=8, max_iter=1000,\n",
              "              random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=64, hidden_layer_sizes=8, max_iter=1000,\n",
              "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=64, hidden_layer_sizes=8, max_iter=1000,\n",
              "              random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "clf_model_2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJr6yNlr2Bym"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 3.2</b><br>\n",
        "Dokonaj prognozy zbioru testowego. <br>\n",
        "Zweryfikuj metryki klasyfikacji trafności, czułości, precyzji itp (np. korzystając z funkcji <code>classification_report</code>).</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJGJQ8_s2Byn"
      },
      "outputs": [],
      "source": [
        "y_pred_2 = clf_model_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waTsYbZd2Byn",
        "outputId": "f4a1366e-f101-4bd4-a3bd-7946a6ae044c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.97      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmUihFNj2Byn"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 4.1</b><br>\n",
        "Korzystając z biblioteki tensorflow, przygotuj architekturę sieci neuronowej o poniższych cechach:\n",
        "<ul>\n",
        "<li>2 warstwy ukryte:</li>\n",
        "    <ul>\n",
        "    <li>pierwsza warstwa ukryta o 16 neuronach</li>\n",
        "    <li>druga warstwa ukryta o 8 neuronach</li>\n",
        "    </ul>\n",
        "<li>funkcja aktywacji dla warstw ukrytych: relu</li>\n",
        "<li>funkcja aktywacji dla warstwy wyjściowej: softmax</li>\n",
        "</ul>\n",
        "\n",
        "❗<b>Ważne:</b> Przed przystąpieniem do modelowania, musimy dodatkowo zakodować etykiety za pomocą kategorii. Wykorzystaj funkcję <code>to_categorical</code> z biblioteki tensorflow.keras.utils\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn1_2jVl2Byo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kafLRfHs2Byp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwT_JUaM2Byp"
      },
      "outputs": [],
      "source": [
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7obkv54PIfD5",
        "outputId": "af8efee6-6348-4d98-8653-cbb3cb9b5ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dense(16, activation='relu', input_shape=(X_train.shape[1]))"
      ],
      "metadata": {
        "id": "TzU7GXCSH-VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1], )))   #Pierwsza warstwa ukryta\n",
        "model.add(Dense(8, activation='relu'))   #Druga warstwa ukryta\n",
        "model.add(Dense(3, activation='softmax'))   #Warstwa wyjściowa"
      ],
      "metadata": {
        "id": "MbcvB2vZHJ6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warstwa wejściowa ma tyle neuronów, ile mamy atrybutów (liczba zmiennych objaśniających), warstwa wyjściowa ma tyle neuronów, ile mamy klas (w klasyfikacji wielowarstwowej)"
      ],
      "metadata": {
        "id": "UgdsYlMBJnGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIruSa0zKGGC",
        "outputId": "aaf91a9e-a4b1-4838-c7fc-b1cc55864316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 16)                224       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 387\n",
            "Trainable params: 387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58Lq33niKGIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oN3CqHA2Byq"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 4.2</b><br>\n",
        "Skompiluj model, wykorzystując:<br>\n",
        "<ul>\n",
        "    <li>optimizer (optymalizator wag neuronów, solver): <i>adam</i></li>\n",
        "<li>funkcję straty: <i>categorical_crossentropy</i></li>\n",
        "<li>metrykę monitorującą: <i>accuracy</i></li>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21gcsIIZ2Byq"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXIGNw4E2Byq"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 4.3</b><br>\n",
        "Wytrenujmy powyższy model. Liczba epok równa 1000 i rozmiar batcha równy 32.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edi7ckc02Byr",
        "outputId": "32d8c2cf-087f-4a30-c276-28feb9346365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.0885 - accuracy: 0.3310\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0476 - accuracy: 0.3662\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.3873\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.4014\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9443 - accuracy: 0.4155\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9153 - accuracy: 0.4296\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8897 - accuracy: 0.4859\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8668 - accuracy: 0.5211\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.5915\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8222 - accuracy: 0.6690\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.7042\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.7606\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7576 - accuracy: 0.7887\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.8028\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.8169\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.8380\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.8380\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.8592\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.8662\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8803\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.9014\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.9014\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.9085\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.9155\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.9296\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.9366\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.9507\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.9507\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.9507\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.9507\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.9507\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.9507\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.9577\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9577\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9577\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2386 - accuracy: 0.9648\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9648\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9648\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9718\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9718\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9718\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9859\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9859\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9859\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9859\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9859\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9859\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9859\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9859\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9930\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9930\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9930\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9930\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9930\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9930\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9930\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9930\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9930\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9930\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9930\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9930\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9930\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9930\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9930\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9930\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9930\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9930\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9930\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9930\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9930\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9930\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9930\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9930\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9930\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9930\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9930\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9930\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9930\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9930\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9930\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9930\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.9463e-04 - accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.8765e-04 - accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.7872e-04 - accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.7081e-04 - accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.6254e-04 - accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.5536e-04 - accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.4709e-04 - accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.4104e-04 - accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.3105e-04 - accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.2832e-04 - accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.1633e-04 - accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0765e-04 - accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0327e-04 - accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.9263e-04 - accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8529e-04 - accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.7800e-04 - accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6977e-04 - accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6400e-04 - accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5579e-04 - accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4891e-04 - accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4271e-04 - accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3565e-04 - accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3010e-04 - accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2286e-04 - accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.1718e-04 - accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1050e-04 - accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0318e-04 - accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.9810e-04 - accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.9251e-04 - accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.8483e-04 - accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.7978e-04 - accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.7341e-04 - accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.6801e-04 - accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.6140e-04 - accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 7.5665e-04 - accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.5196e-04 - accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4595e-04 - accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4065e-04 - accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.3560e-04 - accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.3008e-04 - accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 7.2514e-04 - accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1978e-04 - accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1532e-04 - accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1002e-04 - accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0484e-04 - accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9992e-04 - accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9424e-04 - accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.8947e-04 - accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.8401e-04 - accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7922e-04 - accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7365e-04 - accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.6906e-04 - accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.6401e-04 - accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5908e-04 - accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5521e-04 - accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4911e-04 - accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4475e-04 - accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3995e-04 - accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3539e-04 - accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3039e-04 - accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2639e-04 - accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2214e-04 - accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.1786e-04 - accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.1341e-04 - accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.0910e-04 - accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.0457e-04 - accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.0116e-04 - accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.9659e-04 - accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.9259e-04 - accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.8834e-04 - accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8425e-04 - accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.8047e-04 - accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.7641e-04 - accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.7210e-04 - accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.6875e-04 - accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.6491e-04 - accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.6109e-04 - accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5711e-04 - accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5316e-04 - accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5014e-04 - accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4566e-04 - accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4195e-04 - accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.3925e-04 - accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.3548e-04 - accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.3156e-04 - accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2843e-04 - accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2457e-04 - accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2099e-04 - accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1806e-04 - accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1458e-04 - accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1152e-04 - accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0832e-04 - accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0497e-04 - accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0201e-04 - accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9901e-04 - accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9530e-04 - accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9258e-04 - accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8900e-04 - accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8627e-04 - accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8296e-04 - accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8013e-04 - accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7687e-04 - accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.7398e-04 - accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7119e-04 - accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.6864e-04 - accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.6441e-04 - accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.6151e-04 - accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5897e-04 - accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.5578e-04 - accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5266e-04 - accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.5000e-04 - accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.4771e-04 - accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.4564e-04 - accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.4181e-04 - accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3832e-04 - accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3582e-04 - accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3320e-04 - accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3024e-04 - accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2827e-04 - accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2508e-04 - accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.2249e-04 - accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 4.1968e-04 - accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1689e-04 - accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1450e-04 - accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1190e-04 - accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0954e-04 - accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0731e-04 - accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0481e-04 - accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0281e-04 - accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9950e-04 - accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9720e-04 - accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.9437e-04 - accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.9236e-04 - accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8980e-04 - accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.8749e-04 - accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.8497e-04 - accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8280e-04 - accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.8076e-04 - accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.7817e-04 - accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7624e-04 - accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7395e-04 - accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7188e-04 - accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6948e-04 - accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6707e-04 - accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6504e-04 - accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6263e-04 - accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6117e-04 - accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5876e-04 - accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.5689e-04 - accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5469e-04 - accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.5294e-04 - accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.5044e-04 - accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4885e-04 - accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4674e-04 - accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4466e-04 - accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4270e-04 - accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4095e-04 - accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3824e-04 - accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.3707e-04 - accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 3.3431e-04 - accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3239e-04 - accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3011e-04 - accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2836e-04 - accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2645e-04 - accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2461e-04 - accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2260e-04 - accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2060e-04 - accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1944e-04 - accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1711e-04 - accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1591e-04 - accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1367e-04 - accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1221e-04 - accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1017e-04 - accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0912e-04 - accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0639e-04 - accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.0465e-04 - accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0328e-04 - accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0127e-04 - accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0020e-04 - accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9788e-04 - accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.9614e-04 - accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9448e-04 - accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9278e-04 - accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9128e-04 - accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8970e-04 - accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8815e-04 - accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8666e-04 - accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8499e-04 - accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8371e-04 - accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8193e-04 - accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8073e-04 - accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.7896e-04 - accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.7710e-04 - accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.7594e-04 - accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7442e-04 - accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7272e-04 - accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7113e-04 - accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6982e-04 - accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6838e-04 - accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6686e-04 - accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6531e-04 - accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6385e-04 - accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6292e-04 - accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6136e-04 - accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5955e-04 - accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5819e-04 - accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5698e-04 - accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5540e-04 - accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5421e-04 - accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5293e-04 - accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5164e-04 - accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5006e-04 - accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4877e-04 - accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4767e-04 - accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4630e-04 - accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4497e-04 - accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4370e-04 - accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4242e-04 - accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4115e-04 - accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4021e-04 - accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3883e-04 - accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3780e-04 - accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 2.3637e-04 - accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3511e-04 - accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3367e-04 - accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3291e-04 - accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3129e-04 - accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2989e-04 - accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2844e-04 - accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2731e-04 - accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2616e-04 - accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2491e-04 - accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2384e-04 - accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2272e-04 - accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2166e-04 - accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2056e-04 - accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1928e-04 - accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1839e-04 - accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1723e-04 - accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1638e-04 - accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1515e-04 - accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1400e-04 - accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1305e-04 - accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1194e-04 - accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1088e-04 - accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0973e-04 - accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0863e-04 - accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 2.0781e-04 - accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0698e-04 - accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0566e-04 - accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0448e-04 - accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0342e-04 - accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0245e-04 - accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0146e-04 - accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0052e-04 - accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9944e-04 - accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9828e-04 - accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9751e-04 - accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9622e-04 - accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9507e-04 - accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9414e-04 - accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9333e-04 - accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9218e-04 - accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9125e-04 - accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9011e-04 - accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8929e-04 - accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8829e-04 - accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8742e-04 - accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8652e-04 - accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8554e-04 - accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8451e-04 - accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.8366e-04 - accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8279e-04 - accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8186e-04 - accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8103e-04 - accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.8011e-04 - accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7930e-04 - accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7843e-04 - accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7758e-04 - accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7680e-04 - accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7600e-04 - accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7505e-04 - accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7431e-04 - accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7340e-04 - accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7271e-04 - accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7170e-04 - accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7092e-04 - accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7006e-04 - accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6920e-04 - accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6845e-04 - accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6764e-04 - accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6671e-04 - accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6592e-04 - accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6520e-04 - accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6443e-04 - accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6355e-04 - accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6266e-04 - accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6205e-04 - accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6117e-04 - accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6035e-04 - accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5967e-04 - accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5889e-04 - accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5810e-04 - accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5739e-04 - accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5667e-04 - accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5585e-04 - accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5523e-04 - accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5455e-04 - accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5392e-04 - accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5309e-04 - accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5253e-04 - accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5179e-04 - accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5114e-04 - accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5044e-04 - accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4986e-04 - accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4918e-04 - accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4845e-04 - accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4786e-04 - accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4711e-04 - accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4663e-04 - accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4582e-04 - accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4528e-04 - accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4458e-04 - accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4385e-04 - accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4332e-04 - accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4262e-04 - accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4199e-04 - accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4128e-04 - accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4070e-04 - accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4004e-04 - accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3934e-04 - accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3885e-04 - accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3809e-04 - accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3751e-04 - accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3687e-04 - accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3630e-04 - accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3581e-04 - accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3498e-04 - accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3426e-04 - accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3385e-04 - accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3324e-04 - accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3245e-04 - accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3192e-04 - accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3129e-04 - accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3072e-04 - accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3028e-04 - accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2963e-04 - accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2916e-04 - accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2850e-04 - accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2808e-04 - accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2750e-04 - accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2692e-04 - accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2639e-04 - accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2582e-04 - accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2527e-04 - accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2474e-04 - accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2416e-04 - accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2364e-04 - accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2311e-04 - accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2252e-04 - accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2199e-04 - accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2148e-04 - accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2096e-04 - accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2032e-04 - accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1983e-04 - accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1939e-04 - accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1880e-04 - accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1835e-04 - accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1785e-04 - accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1730e-04 - accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1665e-04 - accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1654e-04 - accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1591e-04 - accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1526e-04 - accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1470e-04 - accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1426e-04 - accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1370e-04 - accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1325e-04 - accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1278e-04 - accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1228e-04 - accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1180e-04 - accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1133e-04 - accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1087e-04 - accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1032e-04 - accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986e-04 - accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0932e-04 - accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0886e-04 - accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0835e-04 - accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0784e-04 - accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0743e-04 - accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0692e-04 - accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0646e-04 - accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0599e-04 - accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0550e-04 - accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0511e-04 - accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0463e-04 - accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0416e-04 - accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0375e-04 - accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0338e-04 - accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0287e-04 - accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0247e-04 - accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0206e-04 - accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0167e-04 - accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0127e-04 - accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0081e-04 - accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0038e-04 - accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.9890e-05 - accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.9438e-05 - accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.8996e-05 - accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.8569e-05 - accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.8069e-05 - accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.7758e-05 - accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.7342e-05 - accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.6965e-05 - accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.6661e-05 - accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.6135e-05 - accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.5694e-05 - accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.5226e-05 - accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.4839e-05 - accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.4444e-05 - accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.4047e-05 - accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.3656e-05 - accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.3350e-05 - accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.2896e-05 - accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.2657e-05 - accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.2053e-05 - accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.1763e-05 - accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.1286e-05 - accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0947e-05 - accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.0511e-05 - accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0164e-05 - accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.9810e-05 - accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.9403e-05 - accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.9115e-05 - accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8699e-05 - accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8323e-05 - accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.7971e-05 - accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7596e-05 - accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7241e-05 - accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6877e-05 - accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6518e-05 - accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.6140e-05 - accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5832e-05 - accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5462e-05 - accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.5044e-05 - accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4717e-05 - accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.4335e-05 - accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4015e-05 - accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3696e-05 - accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3341e-05 - accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2978e-05 - accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2622e-05 - accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2305e-05 - accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1987e-05 - accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1655e-05 - accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.1348e-05 - accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.0966e-05 - accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0676e-05 - accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0396e-05 - accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0119e-05 - accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.9670e-05 - accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.9361e-05 - accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.9037e-05 - accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.8720e-05 - accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.8427e-05 - accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.8109e-05 - accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.7846e-05 - accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.7528e-05 - accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.7234e-05 - accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6948e-05 - accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6632e-05 - accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6363e-05 - accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6070e-05 - accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.5754e-05 - accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.5512e-05 - accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.5230e-05 - accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4926e-05 - accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4637e-05 - accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4369e-05 - accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4058e-05 - accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.3790e-05 - accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.3481e-05 - accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.3169e-05 - accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2850e-05 - accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2567e-05 - accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2261e-05 - accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2002e-05 - accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1688e-05 - accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1426e-05 - accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1182e-05 - accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0886e-05 - accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0655e-05 - accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0391e-05 - accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0111e-05 - accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9810e-05 - accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9582e-05 - accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9282e-05 - accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9016e-05 - accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.8776e-05 - accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 6.8503e-05 - accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.8276e-05 - accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7998e-05 - accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7757e-05 - accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7493e-05 - accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7265e-05 - accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7006e-05 - accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.6761e-05 - accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.6520e-05 - accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.6236e-05 - accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5979e-05 - accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.5751e-05 - accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5472e-05 - accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5302e-05 - accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5009e-05 - accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4767e-05 - accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4500e-05 - accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4277e-05 - accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.4033e-05 - accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3809e-05 - accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.3499e-05 - accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3262e-05 - accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3065e-05 - accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2818e-05 - accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2566e-05 - accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2365e-05 - accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2113e-05 - accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.1901e-05 - accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.1697e-05 - accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.1460e-05 - accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.1238e-05 - accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.1023e-05 - accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6.0794e-05 - accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6.0558e-05 - accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.0339e-05 - accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.0131e-05 - accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.9901e-05 - accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.9682e-05 - accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.9483e-05 - accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.9285e-05 - accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5.9028e-05 - accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8808e-05 - accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8623e-05 - accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8408e-05 - accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.8180e-05 - accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.7920e-05 - accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.7785e-05 - accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.7537e-05 - accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5.7319e-05 - accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.7098e-05 - accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.6904e-05 - accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.6653e-05 - accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.6452e-05 - accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5.6276e-05 - accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.6036e-05 - accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5880e-05 - accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5620e-05 - accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.5381e-05 - accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.5165e-05 - accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4970e-05 - accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.4773e-05 - accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4509e-05 - accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4300e-05 - accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.4079e-05 - accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.3906e-05 - accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.3644e-05 - accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.3400e-05 - accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.3224e-05 - accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.3029e-05 - accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2822e-05 - accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2618e-05 - accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2444e-05 - accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2246e-05 - accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.2079e-05 - accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1881e-05 - accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.1696e-05 - accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.1514e-05 - accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.1334e-05 - accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1144e-05 - accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0958e-05 - accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0775e-05 - accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0601e-05 - accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0402e-05 - accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0194e-05 - accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0008e-05 - accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9815e-05 - accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9623e-05 - accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9451e-05 - accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9246e-05 - accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.9078e-05 - accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8918e-05 - accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8681e-05 - accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8500e-05 - accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8320e-05 - accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8125e-05 - accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7966e-05 - accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7794e-05 - accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.7631e-05 - accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7448e-05 - accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7304e-05 - accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7116e-05 - accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6935e-05 - accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6777e-05 - accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6598e-05 - accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6424e-05 - accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6270e-05 - accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.6097e-05 - accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.5950e-05 - accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5744e-05 - accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5575e-05 - accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5390e-05 - accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5245e-05 - accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5069e-05 - accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4900e-05 - accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4744e-05 - accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4603e-05 - accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4438e-05 - accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4305e-05 - accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4130e-05 - accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3985e-05 - accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3827e-05 - accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3681e-05 - accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3533e-05 - accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3373e-05 - accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.3216e-05 - accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.3084e-05 - accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.2957e-05 - accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.2801e-05 - accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.2632e-05 - accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2470e-05 - accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2300e-05 - accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2148e-05 - accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1979e-05 - accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1831e-05 - accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1678e-05 - accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1531e-05 - accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1380e-05 - accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1238e-05 - accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1088e-05 - accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0937e-05 - accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0814e-05 - accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0677e-05 - accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0519e-05 - accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0382e-05 - accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0271e-05 - accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0117e-05 - accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9957e-05 - accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9831e-05 - accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9688e-05 - accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9542e-05 - accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9406e-05 - accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9260e-05 - accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9117e-05 - accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8965e-05 - accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8805e-05 - accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8688e-05 - accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8519e-05 - accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8428e-05 - accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8288e-05 - accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8087e-05 - accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7942e-05 - accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7836e-05 - accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7674e-05 - accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7546e-05 - accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7408e-05 - accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7267e-05 - accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.7133e-05 - accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6998e-05 - accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6870e-05 - accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6752e-05 - accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6607e-05 - accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6473e-05 - accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6355e-05 - accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6220e-05 - accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6110e-05 - accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5964e-05 - accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5837e-05 - accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5702e-05 - accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5582e-05 - accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5457e-05 - accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5337e-05 - accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5211e-05 - accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5084e-05 - accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4980e-05 - accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4858e-05 - accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4731e-05 - accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.4580e-05 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4475e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ac80bdba0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model.fit(X_train, y_train_cat, batch_size=32, epochs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khRQbowc2Byr"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 4.4</b><br>\n",
        "Dokonaj prognozy zbioru testowego. <br>\n",
        "Zweryfikuj metryki klasyfikacji trafności, czułości, precyzji itp (np. korzystając z funkcji <code>classification_report</code>).</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFfv21B42Byr",
        "outputId": "08483b9b-38e4-4b44-8e09-bb5d7167d25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abW1uMA-2Bys",
        "outputId": "885bdad1-bc03-411a-d6d9-40d0eb5f4034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBBud2U8Mb-v",
        "outputId": "76174551-614f-47bb-e497-8e2cea8c9361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999994e-01, 6.4003852e-10, 3.0503838e-10],\n",
              "       [7.7312277e-04, 8.9837945e-01, 1.0084750e-01],\n",
              "       [9.9999958e-01, 2.2288097e-07, 7.3864165e-08],\n",
              "       [7.9624242e-01, 2.0375079e-01, 6.8466638e-06],\n",
              "       [8.5756647e-06, 9.9998754e-01, 3.8078779e-06],\n",
              "       [9.9999994e-01, 1.4917468e-08, 4.4066524e-09],\n",
              "       [9.9999994e-01, 4.9258690e-09, 4.6215773e-09],\n",
              "       [6.9828357e-06, 9.9999291e-01, 4.3587400e-09],\n",
              "       [4.6242056e-07, 9.9999899e-01, 5.3153877e-07],\n",
              "       [4.0423663e-07, 4.1650825e-08, 9.9999946e-01],\n",
              "       [1.5632681e-05, 9.9998373e-01, 5.9133436e-07],\n",
              "       [1.4670327e-04, 9.9393893e-03, 9.8991388e-01],\n",
              "       [9.9999994e-01, 5.7804245e-10, 1.8609847e-10],\n",
              "       [1.3166951e-03, 1.3765399e-01, 8.6102927e-01],\n",
              "       [9.9999994e-01, 3.8304152e-12, 6.1502197e-12],\n",
              "       [2.7017635e-10, 9.9999994e-01, 1.3631118e-12],\n",
              "       [5.6354419e-09, 9.9999994e-01, 2.7184077e-10],\n",
              "       [9.9999982e-01, 6.1173218e-08, 6.8241146e-09],\n",
              "       [1.2313163e-08, 9.9999994e-01, 4.9115501e-10],\n",
              "       [9.9515522e-01, 4.8333351e-03, 1.1391011e-05],\n",
              "       [7.4794588e-09, 9.9999994e-01, 2.5069849e-11],\n",
              "       [1.3101024e-07, 9.9999970e-01, 1.4486929e-07],\n",
              "       [9.9999982e-01, 1.4039902e-07, 1.3153825e-08],\n",
              "       [9.9999994e-01, 9.2015258e-12, 6.3558686e-11],\n",
              "       [2.4315468e-03, 9.9756807e-01, 3.0276169e-07],\n",
              "       [2.2555970e-09, 9.9999994e-01, 3.0844047e-10],\n",
              "       [9.9999994e-01, 2.2066602e-09, 2.5917928e-09],\n",
              "       [6.9820550e-07, 2.2680313e-06, 9.9999696e-01],\n",
              "       [5.5946424e-05, 9.9991769e-01, 2.6361899e-05],\n",
              "       [3.7327362e-07, 8.3907946e-07, 9.9999875e-01],\n",
              "       [9.9999517e-01, 2.9182404e-06, 1.8897576e-06],\n",
              "       [1.2150408e-06, 2.9047013e-07, 9.9999839e-01],\n",
              "       [1.9532445e-07, 9.9999976e-01, 8.4989815e-10],\n",
              "       [4.0167041e-07, 3.9656189e-08, 9.9999952e-01],\n",
              "       [3.2479815e-07, 8.1940343e-08, 9.9999964e-01],\n",
              "       [7.9799037e-07, 2.8934281e-07, 9.9999893e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_classes = np.argmax(preds, axis=1)"
      ],
      "metadata": {
        "id": "Tc1Abn4OND4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV1GpX9_NLIq",
        "outputId": "62f45f96-0593-44ab-97d6-b49ff0d63491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred=preds_classes, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBj9qnToNWn8",
        "outputId": "3caf5d1c-b5b0-4c57-f070-59f01a1822b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        12\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.94      0.95        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "📝 <b>Zadanie 5.1</b><br>\n",
        "Korzystając z biblioteki tensorflow, przygotuj architekturę sieci neuronowej o poniższych cechach:\n",
        "<ul>\n",
        "<li>1 warstwa ukryta:</li>\n",
        "    <ul>\n",
        "    <li>pierwsza warstwa ukryta o 8 neuronach</li>\n",
        "    </ul>\n",
        "<li>funkcja aktywacji dla warstw ukrytych: relu</li>\n",
        "<li>funkcja aktywacji dla warstwy wyjściowej: softmax</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "pOGe4TY3OtZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "R_Lw46WSO4AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(units =8, activation = 'relu', input_shape =(X_train.shape[1], ))) #pierwsza warstwa ukryta\n",
        "model.add(Dense(units =3, activation = 'softmax')) # warstwa wyjsciowa"
      ],
      "metadata": {
        "id": "hR89ec0mPFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(y)   #3 klasy więc 3 jako warstwa wyjściowa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaEYqly2Q8LZ",
        "outputId": "66a63ad0-73f0-4c2c-c15f-f2722057bba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxHr4yZ6PacK",
        "outputId": "d8aa2b64-d088-41dc-9510-a704a83b25ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 8)                 112       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "oblM2csQRHTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train_cat, batch_size=32, epochs=1000, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLnWOhM2RRwn",
        "outputId": "4347b9b3-8311-4aa7-e266-ba1b2c181160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ac8065390>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)\n",
        "preds_classes = np.argmax(preds, axis=1)\n",
        "print(classification_report(y_pred=preds_classes, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU1AcwbeRWPE",
        "outputId": "3c66f147-a2fc-438a-c48a-3087a8ebfa0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py38ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d82f3bafc0bfe26145b4b4405506cfdddd6cc205e24f6709dc9baaf0c1c8ebbd"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}